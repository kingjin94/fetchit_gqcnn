# sensor params
sensor:
  # image_dir: data/rgbd/multiple_objects
  image_dir: /root/catkin_ws/src/fetchit_gqcnn/src
  type: virtual
  frame: primesense_overhead
calib_dir:  /root/catkin_ws/src/fetchit_gqcnn/src

# policy params
policy:
  # gqcnn params
  gqcnn_model: /root/catkin_ws/src/gqcnn/models
  
  # optimization params, see gqcnn/policy.py::CrossEntropyAntipodalGraspingPolicy for details
  num_seed_samples: 400 # was 200, increase to get more samples of the robot
  num_gmm_samples: 50
  num_iters: 4 # was 3, convergence to interesting object so far only in 3rd itter
  gmm_refit_p: 0.35 # was 0.25
  gmm_component_frac: 0.4
  gmm_reg_covar: 0.01

  # general params
  deterministic: 0
  gripper_width: 0.1 # Fetch has 10 cm gripper, not original 5 cm
  crop_height: 128   # Does not help if object to big for single CNN look --> change 96 to 128
  crop_width: 128

  # sampling params
  sampling:
    # type
    type: antipodal_depth

    # antipodality
    friction_coef: 1.0
    depth_grad_thresh: 0.0025
    depth_grad_gaussian_sigma: 1.0
    downsample_rate: 4
    max_rejection_samples: 4000

    # distance
    max_dist_from_center: 400 #160
    min_dist_from_boundary: 45
    min_grasp_dist: 2.5
    angle_dist_weight: 5.0

    # depth sampling
    depth_samples_per_grasp: 1
    depth_sample_win_height: 1
    depth_sample_win_width: 1
    min_depth_offset: 0.015
    max_depth_offset: 0.05

  # visualization
  vis:
    grasp_sampling : 0
    tf_images: 0
    grasp_candidates: 0 # was 1, shows substeps
    elite_grasps: 0
    grasp_ranking: 0
    grasp_plan: 0 # shows closeup of final grasp
    final_grasp: 1

    k: 25

# image proc params
inpaint_rescale_factor: 0.5

